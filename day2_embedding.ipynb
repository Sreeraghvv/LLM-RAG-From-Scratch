{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21daf6c5-7092-4f1e-be96-8929f4b8929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers faiss-cpu numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e5b3f9-96dd-4b27-97fd-8626f3714a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6566c625-1137-4b81-9de9-fa9d178e3874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f92499dfd3e41ba8fb74d8582159b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e71885c72fd461ba61d7c703bac25f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cd34dca68a4354a25693b54f734aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1210d455c76a461f808359d879ab2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259192c69ca04c23a0e02505b576601b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4596f4e274ff490db2c8205faf1e074f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27873e4dc734193b15a14508654939a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e982f0e2ade64476a85325c0a45435f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d8c805a1fa4627bfb4253e4b12ad4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc48eb8bf8442eea13354ddd1298a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf3012e59e54c5bb6b9763f59f5c670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7df86a2679e4234b6172ed4481835b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5e6331f-2cb9-4907-b42b-a029b93d9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 6\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is powerful\",\n",
    "    \"Deep learning uses neural networks\",\n",
    "    \"The cat is sleeping on the sofa\",\n",
    "    \"Artificial intelligence is the future\",\n",
    "    \"Dogs are loyal animals\",\n",
    "    \"Transformers changed NLP forever\"\n",
    "]\n",
    "\n",
    "print(\"Total documents:\", len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ffd8542-fd24-4538-b781-6f9c9ce537fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (6, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(\"Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61637a25-cb60-478f-94c1-c6716a20ed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors stored in FAISS: 6\n"
     ]
    }
   ],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dimension)  # Exact search using L2 distance\n",
    "\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "print(\"Total vectors stored in FAISS:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1d6355-848f-4bf2-b356-884d4c6ca580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=2):\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    distances, indices = index.search(np.array(query_embedding), k)\n",
    "    \n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\\nTop Matches:\")\n",
    "    \n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"{i+1}. {documents[idx]} (Distance: {distances[0][i]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad3e778-0916-44b9-988c-48db748fbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Dogs are loyal animals\n",
      "\n",
      "Top Matches:\n",
      "1. Dogs are loyal animals (Distance: 0.0000)\n",
      "2. The cat is sleeping on the sofa (Distance: 1.8799)\n",
      "3. Deep learning uses neural networks (Distance: 1.9058)\n"
     ]
    }
   ],
   "source": [
    "search(\"Dogs are loyal animals\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1995dded-b193-470e-94c3-dce4841e5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with random vectors (should be meaningless):\n",
      "Transformers changed NLP forever\n",
      "Machine learning is powerful\n"
     ]
    }
   ],
   "source": [
    "# Test Failure (Random Vectors)\n",
    "random_vectors = np.random.rand(len(documents), dimension).astype('float32')\n",
    "\n",
    "random_index = faiss.IndexFlatL2(dimension)\n",
    "random_index.add(random_vectors)\n",
    "\n",
    "query_embedding = model.encode([\"Dogs are loyal animals\"])\n",
    "\n",
    "distances, indices = random_index.search(np.array(query_embedding), 2)\n",
    "\n",
    "print(\"Results with random vectors (should be meaningless):\")\n",
    "for idx in indices[0]:\n",
    "    print(documents[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c663b972-e730-4816-9c3f-71e41849e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Scores:\n",
      "Machine learning is powerful --> 0.5515\n",
      "Deep learning uses neural networks --> 0.4103\n",
      "The cat is sleeping on the sofa --> -0.0959\n",
      "Artificial intelligence is the future --> 0.7053\n",
      "Dogs are loyal animals --> 0.0863\n",
      "Transformers changed NLP forever --> 0.1659\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = \"Artificial intelligence\"\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "\n",
    "print(\"Cosine Similarity Scores:\")\n",
    "for doc, score in zip(documents, similarities[0]):\n",
    "    print(f\"{doc} --> {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb25eb-d11f-434e-a7fb-8d91cd77011b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
