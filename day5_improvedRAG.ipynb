{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5b3b00-2b6f-41a6-8852-82a87c112248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers faiss-cpu PyPDF2 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea28e96-45e8-4cd0-919a-eef7eabd5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318991fe-8a88-40f7-95f9-058ecb2be10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4968100ba1d64feba087aa73d1f95462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ef14f8435947b382e1fe0602a1f531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Loading reranker model...\")\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "print(\"Models loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0401569-c284-49fb-831e-730769c7cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_metadata(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    \n",
    "    for page_number, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            pages.append({\n",
    "                \"page_number\": page_number,\n",
    "                \"text\": text\n",
    "            })\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d617c6c-f7ed-4f76-8b1f-cb30b8517827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_pages(pages, pdf_name, chunk_size=300, overlap=50):\n",
    "    metadata_store = []\n",
    "    \n",
    "    for page in pages:\n",
    "        text = page[\"text\"]\n",
    "        page_number = page[\"page_number\"]\n",
    "        \n",
    "        start = 0\n",
    "        chunk_index = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + chunk_size\n",
    "            chunk_text = text[start:end]\n",
    "            \n",
    "            metadata_store.append({\n",
    "                \"chunk_id\": f\"{pdf_name}_page_{page_number}_chunk_{chunk_index}\",\n",
    "                \"document_name\": pdf_name,\n",
    "                \"page_number\": page_number,\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"text\": chunk_text\n",
    "            })\n",
    "            \n",
    "            start += chunk_size - overlap\n",
    "            chunk_index += 1\n",
    "            \n",
    "    return metadata_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6f841d-9a16-4dd0-b609-768336f03f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 6\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"sample.pdf\"\n",
    "pdf_name = os.path.basename(pdf_path)\n",
    "\n",
    "pages = extract_text_with_metadata(pdf_path)\n",
    "metadata_store = chunk_pages(pages, pdf_name)\n",
    "\n",
    "print(\"Total chunks created:\", len(metadata_store))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf147f09-3a42-47de-9789-9bba67c7f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built.\n"
     ]
    }
   ],
   "source": [
    "chunk_texts = [item[\"text\"] for item in metadata_store]\n",
    "\n",
    "embeddings = embedding_model.encode(chunk_texts)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6b5e8a-0d8f-443f-bb27-625e0113111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=8):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            \"text\": metadata_store[idx][\"text\"],\n",
    "            \"page_number\": metadata_store[idx][\"page_number\"],\n",
    "            \"score\": float(distances[0][i])\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111d1b6d-562b-448a-a67a-4519c2d8633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.3\n",
    "\n",
    "def filter_by_threshold(retrieved_chunks):\n",
    "    filtered = [\n",
    "        chunk for chunk in retrieved_chunks\n",
    "        if chunk[\"score\"] >= SIMILARITY_THRESHOLD\n",
    "    ]\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55722aa-21f1-4f6c-924e-8645ee4bb474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(query, retrieved_chunks):\n",
    "    if len(retrieved_chunks) == 0:\n",
    "        return []\n",
    "    \n",
    "    pairs = [(query, chunk[\"text\"]) for chunk in retrieved_chunks]\n",
    "    scores = reranker.predict(pairs)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        retrieved_chunks[i][\"rerank_score\"] = float(score)\n",
    "    \n",
    "    reranked = sorted(\n",
    "        retrieved_chunks,\n",
    "        key=lambda x: x[\"rerank_score\"],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return reranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8aee442-7611-412f-8c5c-a6d75422f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, selected_chunks):\n",
    "    context = \"\\n\\n\".join(\n",
    "        [chunk[\"text\"] for chunk in selected_chunks]\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Use ONLY the provided context to answer the question.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1ca933-5173-423b-90b0-05f34fde8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    return response.json()[\"response\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb64a8bb-dacc-4ef7-b543-1f052e4050d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_v2(query, retrieve_k=8, final_k=3):\n",
    "    \n",
    "    print(\"\\nUser Question:\", query)\n",
    "    \n",
    "    # Step 1: Retrieve\n",
    "    retrieved = retrieve(query, k=retrieve_k)\n",
    "    print(f\"\\nRetrieved {len(retrieved)} chunks\")\n",
    "    \n",
    "    # Step 2: Filter\n",
    "    filtered = filter_by_threshold(retrieved)\n",
    "    print(f\"After threshold filtering: {len(filtered)} chunks\")\n",
    "    \n",
    "    # Step 3: Re-rank\n",
    "    reranked = rerank(query, filtered)\n",
    "    \n",
    "    # Step 4: Select top final_k\n",
    "    selected = reranked[:final_k]\n",
    "    \n",
    "    print(\"\\nTop Selected Chunks After Re-ranking:\\n\")\n",
    "    for i, chunk in enumerate(selected):\n",
    "        print(f\"Rank {i+1}\")\n",
    "        print(\"Page:\", chunk[\"page_number\"])\n",
    "        print(\"Similarity Score:\", round(chunk[\"score\"], 4))\n",
    "        print(\"Rerank Score:\", round(chunk[\"rerank_score\"], 4))\n",
    "        print(chunk[\"text\"][:200])\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Step 5: Build prompt\n",
    "    prompt = build_prompt(query, selected)\n",
    "    \n",
    "    # Step 6: Generate answer\n",
    "    answer = generate_answer(prompt)\n",
    "    \n",
    "    print(\"\\nFinal Answer:\\n\")\n",
    "    print(answer)\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0820cf36-4430-4e52-8a39-9115dc07ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Question: What are applications of machine learning?\n",
      "\n",
      "Retrieved 8 chunks\n",
      "After threshold filtering: 6 chunks\n",
      "\n",
      "Top Selected Chunks After Re-ranking:\n",
      "\n",
      "Rank 1\n",
      "Page: 0\n",
      "Similarity Score: 0.7361\n",
      "Rerank Score: 9.0974\n",
      "eled data, and reinforcement learning\n",
      "learns through rewards and penalties. Applications of machine learning include recommendation\n",
      "systems, fraud detection, natural language processing, computer visi\n",
      "------------------------------------------------------------\n",
      "Rank 2\n",
      "Page: 0\n",
      "Similarity Score: 0.6534\n",
      "Rerank Score: 5.378\n",
      "Introduction to Machine Learning\n",
      "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from\n",
      "data. Instead of being explicitly programmed with rules, machi\n",
      "------------------------------------------------------------\n",
      "Rank 3\n",
      "Page: 0\n",
      "Similarity Score: 0.5746\n",
      "Rerank Score: 4.1344\n",
      "sions based on historical information. There are three main types of machine learning:\n",
      "supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses\n",
      "labeled data, un\n",
      "------------------------------------------------------------\n",
      "\n",
      "Final Answer:\n",
      "\n",
      " Applications of machine learning include recommendation systems, fraud detection, natural language processing, computer vision, and predictive analytics.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Applications of machine learning include recommendation systems, fraud detection, natural language processing, computer vision, and predictive analytics.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_v2(\n",
    "    \"What are applications of machine learning?\",\n",
    "    retrieve_k=8,\n",
    "    final_k=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77c1ca-620b-40eb-8df4-fe645defe4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
