{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacf0708-94a4-49f6-9327-19bc1b49d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers faiss-cpu ollama pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff767501-5bbf-4eb1-a23c-751d032a23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee829423-6a26-4029-b1b2-5f9e9854ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b98657c40e48c39f5a82e99164d502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf1f25c-be4b-458d-b085-613444515022",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence that enables systems to learn from data.\",\n",
    "    \"Supervised learning uses labeled data to train models.\",\n",
    "    \"Unsupervised learning works with unlabeled data.\",\n",
    "    \"Reinforcement learning learns through rewards and penalties.\",\n",
    "    \"Applications of machine learning include recommendation systems, fraud detection, natural language processing, computer vision, and predictive analytics.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303838c7-912b-4337-90b0-1d09336b1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.encode(documents)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "faiss.normalize_L2(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67375524-9165-4b5c-a32e-f1c8603ce51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5944103-b046-4fe7-b84c-a0b49c4f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=5):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            \"text\": documents[idx],\n",
    "            \"score\": distances[0][i]\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065a7f53-bd79-4598-b19e-9ff9d66a577f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba5ef926df642da99f0cb026832ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank(query, retrieved_chunks):\n",
    "    pairs = [(query, chunk[\"text\"]) for chunk in retrieved_chunks]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    for i, score in enumerate(scores):\n",
    "        retrieved_chunks[i][\"rerank_score\"] = score\n",
    "\n",
    "    return sorted(retrieved_chunks, key=lambda x: x[\"rerank_score\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ffc30c5-c4ef-4c57-8d4a-0066cbdda6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context):\n",
    "    prompt = f\"\"\"\n",
    "Answer the question strictly using the provided context.\n",
    "If the answer is not in the context, say \"Not found in context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1426c169-5752-48ca-ace8-e1a827f766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_faithfulness(query, context, answer):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are evaluating a RAG system.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Does the answer contain any information NOT supported by the context?\n",
    "Reply with:\n",
    "Score: 1 (Not faithful) to 5 (Fully faithful)\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6947f98-cd55-47ed-8562-72153a659ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_relevance(query, answer):\n",
    "    eval_prompt = f\"\"\"\n",
    "Evaluate how well the answer addresses the question.\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Reply strictly in this format:\n",
    "Score: <number between 1 and 5>\n",
    "Explanation: <brief reason>\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"num_gpu\": 0  # Force CPU to avoid CUDA crash\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32ae79ea-b876-430a-acf4-7a72ce8201a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"What are applications of machine learning?\",\n",
    "    \"Define supervised learning.\",\n",
    "    \"Explain reinforcement learning.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170c6119-b8ab-452c-898f-69c8b7c679b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Question: What are applications of machine learning?\n",
      "Answer: According to the provided context, the answer is:\n",
      "\n",
      "Recommendation systems, fraud detection, natural language processing, computer vision, and predictive analytics.\n",
      "Faithfulness: Score: 5 (Fully faithful)\n",
      "\n",
      "The answer provided contains all the applications of machine learning mentioned in the given context, and does not include any additional or unrelated information. The answer is a direct summary of the provided context, making it fully faithful.\n",
      "Relevance: Score: 4\n",
      "Explanation: The answer provides a list of specific applications of machine learning, which directly addresses the question. However, it would be more comprehensive if it included a brief explanation or examples for each application to further illustrate their relevance and importance.\n",
      "\n",
      "==============================\n",
      "Question: Define supervised learning.\n",
      "Answer: According to the provided context, the answer is:\n",
      "\n",
      "\"Uses labeled data to train models.\"\n",
      "Faithfulness: I'd rate this answer a 5 (Fully faithful).\n",
      "\n",
      "The provided context states that \"Supervised learning uses labeled data to train models.\" The answer directly quotes this statement, providing an exact definition of supervised learning. There is no information in the answer that is not supported by the context.\n",
      "Relevance: Score: 4\n",
      "Explanation: The answer provides a clear and concise definition of supervised learning, which is accurate. However, it would be more comprehensive if the answer also explained what labeled data means or provided an example to illustrate the concept.\n",
      "\n",
      "==============================\n",
      "Question: Explain reinforcement learning.\n",
      "Answer: Reinforcement learning learns through rewards and penalties.\n",
      "Faithfulness: Score: 5 (Fully faithful)\n",
      "\n",
      "The answer directly quotes the given context, \"Reinforcement learning learns through rewards and penalties.\" This indicates that the answer is fully faithful to the provided context. There is no additional information or interpretation added that is not supported by the original text. The answer accurately reflects the definition of reinforcement learning as described in the context.\n",
      "Relevance: Score: 2\n",
      "Explanation: The answer only provides a vague definition of reinforcement learning, without explaining the underlying mechanisms or providing any concrete examples. It does not address the complexity and nuances of the topic.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Question:\", question)\n",
    "\n",
    "    retrieved = retrieve(question, k=5)\n",
    "    reranked = rerank(question, retrieved)\n",
    "    top_chunks = reranked[:3]\n",
    "\n",
    "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in top_chunks])\n",
    "\n",
    "    answer = generate_answer(question, context)\n",
    "\n",
    "    faithfulness = evaluate_faithfulness(question, context, answer)\n",
    "    relevance = evaluate_relevance(question, answer)\n",
    "\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"Answer\": answer,\n",
    "        \"Faithfulness\": faithfulness,\n",
    "        \"Relevance\": relevance\n",
    "    })\n",
    "\n",
    "    print(\"Answer:\", answer)\n",
    "    print(\"Faithfulness:\", faithfulness)\n",
    "    print(\"Relevance:\", relevance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c48c788-c2cc-4ad1-a5ca-4d09d7f5f3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are applications of machine learning?</td>\n",
       "      <td>According to the provided context, the answer ...</td>\n",
       "      <td>Score: 5 (Fully faithful)\\n\\nThe answer provid...</td>\n",
       "      <td>Score: 4\\nExplanation: The answer provides a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Define supervised learning.</td>\n",
       "      <td>According to the provided context, the answer ...</td>\n",
       "      <td>I'd rate this answer a 5 (Fully faithful).\\n\\n...</td>\n",
       "      <td>Score: 4\\nExplanation: The answer provides a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain reinforcement learning.</td>\n",
       "      <td>Reinforcement learning learns through rewards ...</td>\n",
       "      <td>Score: 5 (Fully faithful)\\n\\nThe answer direct...</td>\n",
       "      <td>Score: 2\\nExplanation: The answer only provide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Question  \\\n",
       "0  What are applications of machine learning?   \n",
       "1                 Define supervised learning.   \n",
       "2             Explain reinforcement learning.   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  According to the provided context, the answer ...   \n",
       "1  According to the provided context, the answer ...   \n",
       "2  Reinforcement learning learns through rewards ...   \n",
       "\n",
       "                                        Faithfulness  \\\n",
       "0  Score: 5 (Fully faithful)\\n\\nThe answer provid...   \n",
       "1  I'd rate this answer a 5 (Fully faithful).\\n\\n...   \n",
       "2  Score: 5 (Fully faithful)\\n\\nThe answer direct...   \n",
       "\n",
       "                                           Relevance  \n",
       "0  Score: 4\\nExplanation: The answer provides a l...  \n",
       "1  Score: 4\\nExplanation: The answer provides a c...  \n",
       "2  Score: 2\\nExplanation: The answer only provide...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"evaluation_report.csv\", index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee66a46-f9d9-44df-82cb-c6a9c8e692f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65423ee-1078-4dbb-87fc-a6b42b48b0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449de618-3d60-4a9f-93d3-e0ec88d29d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c2761-7e28-47be-b6e9-7d96f62a5c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93411f5-7258-40cc-915c-9817f83e9758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f9c33-589d-462a-a4f9-64b27278b8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10181a-868d-41f7-b4a5-1c174a2087b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804af6c1-cc51-4256-82c3-02376c92fdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4b268-8a89-402b-a470-cc9880857098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
