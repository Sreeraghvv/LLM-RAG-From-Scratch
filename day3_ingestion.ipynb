{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b97783-877d-4868-ac11-70ac5c4de31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.13.2)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (8.1.8)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca4b55e1-3ce3-42c6-87ac-94c19aa44616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a3e1fb-4e31-44c0-bab8-502e088fa388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97638e1ac1664f55b6cdff383b903bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6faceed8-004c-479a-9b31-862270d64a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_metadata(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    \n",
    "    for page_number, page in enumerate(reader.pages):\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            pages.append({\n",
    "                \"page_number\": page_number,\n",
    "                \"text\": page_text\n",
    "            })\n",
    "    \n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "237c0a89-9780-435c-a20c-119131f8e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_pages(pages, pdf_name, chunk_size=300, overlap=50):\n",
    "    metadata_store = []\n",
    "    \n",
    "    for page in pages:\n",
    "        text = page[\"text\"]\n",
    "        page_number = page[\"page_number\"]\n",
    "        \n",
    "        start = 0\n",
    "        chunk_index = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + chunk_size\n",
    "            chunk_text = text[start:end]\n",
    "            \n",
    "            metadata_store.append({\n",
    "                \"chunk_id\": f\"{pdf_name}_page_{page_number}_chunk_{chunk_index}\",\n",
    "                \"document_name\": pdf_name,\n",
    "                \"page_number\": page_number,\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"text\": chunk_text\n",
    "            })\n",
    "            \n",
    "            start += chunk_size - overlap\n",
    "            chunk_index += 1\n",
    "    \n",
    "    return metadata_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8bd69ef-c950-4d80-a08b-b5637041a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text...\n",
      "Chunking text...\n",
      "Total chunks created: 6\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"sample.pdf\"\n",
    "pdf_name = os.path.basename(pdf_path)\n",
    "\n",
    "print(\"Extracting text...\")\n",
    "pages = extract_text_with_metadata(pdf_path)\n",
    "\n",
    "print(\"Chunking text...\")\n",
    "metadata_store = chunk_pages(pages, pdf_name)\n",
    "\n",
    "print(\"Total chunks created:\", len(metadata_store))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfae1bb-6ce7-44e1-9d47-00327df61103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "Embedding shape: (6, 384)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating embeddings...\")\n",
    "\n",
    "chunk_texts = [item[\"text\"] for item in metadata_store]\n",
    "\n",
    "embeddings = model.encode(chunk_texts)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "print(\"Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f20b419d-ce40-42d9-9c54-2d2f2ad59b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built successfully\n",
      "Total vectors: 6\n"
     ]
    }
   ],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index built successfully\")\n",
    "print(\"Total vectors:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db9c6c1b-f248-4e0c-8980-1ed315c05251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=3):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    query_embedding = model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "    \n",
    "    # Normalize query embedding\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    print(\"\\nTop Results:\\n\")\n",
    "    \n",
    "    for rank, idx in enumerate(indices[0]):\n",
    "        result = metadata_store[idx]\n",
    "        \n",
    "        print(f\"Result {rank+1}\")\n",
    "        print(\"Chunk ID:\", result[\"chunk_id\"])\n",
    "        print(\"Document:\", result[\"document_name\"])\n",
    "        print(\"Page:\", result[\"page_number\"])\n",
    "        print(\"Chunk Index:\", result[\"chunk_index\"])\n",
    "        print(\"Cosine Similarity:\", distances[0][rank])\n",
    "        print(\"Text Preview:\", result[\"text\"][:200])\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47247881-a6e9-478c-bb44-964a70224ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: machine learning applications\n",
      "\n",
      "Top Results:\n",
      "\n",
      "Result 1\n",
      "Chunk ID: sample.pdf_page_0_chunk_2\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 2\n",
      "Cosine Similarity: 0.63057566\n",
      "Text Preview: eled data, and reinforcement learning\n",
      "learns through rewards and penalties. Applications of machine learning include recommendation\n",
      "systems, fraud detection, natural language processing, computer visi\n",
      "------------------------------------------------------------\n",
      "Result 2\n",
      "Chunk ID: sample.pdf_page_0_chunk_0\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 0\n",
      "Cosine Similarity: 0.5897626\n",
      "Text Preview: Introduction to Machine Learning\n",
      "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from\n",
      "data. Instead of being explicitly programmed with rules, machi\n",
      "------------------------------------------------------------\n",
      "Result 3\n",
      "Chunk ID: sample.pdf_page_0_chunk_1\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 1\n",
      "Cosine Similarity: 0.50739974\n",
      "Text Preview: sions based on historical information. There are three main types of machine learning:\n",
      "supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses\n",
      "labeled data, un\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: recommendation systems\n",
      "\n",
      "Top Results:\n",
      "\n",
      "Result 1\n",
      "Chunk ID: sample.pdf_page_0_chunk_2\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 2\n",
      "Cosine Similarity: 0.29882118\n",
      "Text Preview: eled data, and reinforcement learning\n",
      "learns through rewards and penalties. Applications of machine learning include recommendation\n",
      "systems, fraud detection, natural language processing, computer visi\n",
      "------------------------------------------------------------\n",
      "Result 2\n",
      "Chunk ID: sample.pdf_page_0_chunk_0\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 0\n",
      "Cosine Similarity: 0.28248787\n",
      "Text Preview: Introduction to Machine Learning\n",
      "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from\n",
      "data. Instead of being explicitly programmed with rules, machi\n",
      "------------------------------------------------------------\n",
      "Result 3\n",
      "Chunk ID: sample.pdf_page_0_chunk_1\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 1\n",
      "Cosine Similarity: 0.22431764\n",
      "Text Preview: sions based on historical information. There are three main types of machine learning:\n",
      "supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses\n",
      "labeled data, un\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: neural networks\n",
      "\n",
      "Top Results:\n",
      "\n",
      "Result 1\n",
      "Chunk ID: sample.pdf_page_0_chunk_4\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 4\n",
      "Cosine Similarity: 0.5769595\n",
      "Text Preview: an automatically learn hierarchical representations of data. Neural\n",
      "networks are inspired by the human brain and consist of layers of interconnected neurons. Each neuron\n",
      "applies a mathematical transfo\n",
      "------------------------------------------------------------\n",
      "Result 2\n",
      "Chunk ID: sample.pdf_page_0_chunk_3\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 3\n",
      "Cosine Similarity: 0.54633033\n",
      "Text Preview: ne learning systems become more powerful and capable of solving complex\n",
      "problems.\n",
      "Deep Learning and Neural Networks\n",
      "Deep learning is a specialized branch of machine learning that uses neural networks \n",
      "------------------------------------------------------------\n",
      "Result 3\n",
      "Chunk ID: sample.pdf_page_0_chunk_5\n",
      "Document: sample.pdf\n",
      "Page: 0\n",
      "Chunk Index: 5\n",
      "Cosine Similarity: 0.44865662\n",
      "Text Preview: next layer. Deep learning\n",
      "has enabled breakthroughs in image recognition, speech recognition, and large language models. It is\n",
      "the foundation of many modern AI systems.\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "search(\"machine learning applications\")\n",
    "search(\"recommendation systems\")\n",
    "search(\"neural networks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372c2eb-caa9-4848-b2b5-3cfe93925b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
